{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data_train = pd.read_csv(\"Para_Vectors.csv\").values\n",
    "y = pd.read_csv(\"one_hot.csv\").values\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.036828   0.017651  -0.061462  ... -0.025613  -0.026035  -0.0082699]\n",
      " [-0.024642   0.017967  -0.062718  ... -0.01925   -0.026181  -0.012447 ]\n",
      " [-0.02029    0.016148  -0.060996  ... -0.027124  -0.025393  -0.011114 ]\n",
      " ...\n",
      " [-0.02602    0.016331  -0.082829  ... -0.022514  -0.03231   -0.014532 ]\n",
      " [-0.029274   0.020095  -0.082125  ... -0.026341  -0.01862   -0.010734 ]\n",
      " [-0.023376   0.018064  -0.067972  ... -0.020067  -0.028426  -0.024695 ]]\n"
     ]
    }
   ],
   "source": [
    "print(data_train[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 21)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = []\n",
    "for i in range(0,21):\n",
    "    z.append(y[:,i])\n",
    "#z = y[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 21)\n"
     ]
    }
   ],
   "source": [
    "z = np.array(z.T)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_train[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 300)\n",
      "(252, 21)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "1\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "1.0\n",
      "2\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "3\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "4\n",
      "Training accuracy: \n",
      "0.9417989417989417\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "5\n",
      "Training accuracy: \n",
      "0.9576719576719577\n",
      "Testing accuracy\n",
      "0.9523809523809523\n",
      "6\n",
      "Training accuracy: \n",
      "0.9576719576719577\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "7\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "8\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "1.0\n",
      "9\n",
      "Training accuracy: \n",
      "0.9629629629629629\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "10\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "11\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "12\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "13\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "1.0\n",
      "14\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "15\n",
      "Training accuracy: \n",
      "0.6349206349206349\n",
      "Testing accuracy\n",
      "0.6825396825396826\n",
      "16\n",
      "Training accuracy: \n",
      "0.7513227513227513\n",
      "Testing accuracy\n",
      "0.7301587301587301\n",
      "17\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "1.0\n",
      "18\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "19\n",
      "Training accuracy: \n",
      "0.9629629629629629\n",
      "Testing accuracy\n",
      "0.9206349206349206\n",
      "20\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "Avg_training_accuracy 0.9516250944822373\n",
      "Avg_testing_accuracy 0.9546485260770975\n"
     ]
    }
   ],
   "source": [
    "Train_accuracy = 0\n",
    "Test_accuracy = 0\n",
    "for i in range(0,21):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, z[:,i])\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    print(\"Training accuracy: \")\n",
    "    print(metrics.accuracy_score(y_train,y_pred1))\n",
    "    Train_accuracy = Train_accuracy + metrics.accuracy_score(y_train,y_pred1)\n",
    "    print(\"Testing accuracy\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred2))\n",
    "    Test_accuracy = Test_accuracy + metrics.accuracy_score(y_test,y_pred2)\n",
    "    #print(y_train.shape)\n",
    "Avg_tr_acc = Train_accuracy/21\n",
    "Avg_te_acc = Test_accuracy/21\n",
    "print(\"Avg_training_accuracy\",Avg_tr_acc)\n",
    "print(\"Avg_testing_accuracy\",Avg_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: \n",
      "0.671957671957672\n",
      "Testing accuracy\n",
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "y_pred1 = clf.predict(X_train)\n",
    "y_pred2 = clf.predict(X_test)\n",
    "print(\"Training accuracy: \")\n",
    "print(metrics.accuracy_score(y_train,y_pred1))\n",
    "print(\"Testing accuracy\")\n",
    "print(metrics.accuracy_score(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train_accuracy = 0\n",
    "Test_accuracy = 0\n",
    "for i in range(0,21):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, z[:,i])\n",
    "    clf = SVC()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    print(\"Training accuracy: \")\n",
    "    print(metrics.accuracy_score(y_train,y_pred1))\n",
    "    Train_accuracy = Train_accuracy + metrics.accuracy_score(y_train,y_pred1)\n",
    "    print(\"Testing accuracy\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred2))\n",
    "    Test_accuracy = Test_accuracy + metrics.accuracy_score(y_test,y_pred2)\n",
    "    #print(y_train.shape)\n",
    "Avg_tr_acc = Train_accuracy/21\n",
    "Avg_te_acc = Test_accuracy/21\n",
    "print(Avg_tr_acc)\n",
    "print(Avg_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "1.0\n",
      "1\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "2\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "1.0\n",
      "3\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "4\n",
      "Training accuracy: \n",
      "0.9417989417989417\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "5\n",
      "Training accuracy: \n",
      "0.9629629629629629\n",
      "Testing accuracy\n",
      "0.9365079365079365\n",
      "6\n",
      "Training accuracy: \n",
      "0.9523809523809523\n",
      "Testing accuracy\n",
      "1.0\n",
      "7\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "8\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-3c846dc3f848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#print(clf.predict(data_test))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    851\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m    852\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "Train_accuracy = 0\n",
    "Test_accuracy = 0\n",
    "for i in range(0,21):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, z[:,i])\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "    y_pred1 = clf.predict(X_train)\n",
    "    y_pred2 = clf.predict(X_test)\n",
    "    print(\"Training accuracy: \")\n",
    "    print(metrics.accuracy_score(y_train,y_pred1))\n",
    "    Train_accuracy = Train_accuracy + metrics.accuracy_score(y_train,y_pred1)\n",
    "    print(\"Testing accuracy\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred2))\n",
    "    Test_accuracy = Test_accuracy + metrics.accuracy_score(y_test,y_pred2)\n",
    "    #print(y_train.shape)\n",
    "Avg_tr_acc = Train_accuracy/21\n",
    "Avg_te_acc = Test_accuracy/21\n",
    "print(\"Avg_training_accuracy\",Avg_tr_acc)\n",
    "print(\"Avg_testing_accuracy\",Avg_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "1\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "1.0\n",
      "2\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "1.0\n",
      "3\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "4\n",
      "Training accuracy: \n",
      "0.9576719576719577\n",
      "Testing accuracy\n",
      "0.9365079365079365\n",
      "5\n",
      "Training accuracy: \n",
      "0.9417989417989417\n",
      "Testing accuracy\n",
      "1.0\n",
      "6\n",
      "Training accuracy: \n",
      "0.9629629629629629\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "7\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "8\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "1.0\n",
      "9\n",
      "Training accuracy: \n",
      "0.9682539682539683\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "10\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "11\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "12\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "13\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "1.0\n",
      "14\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "15\n",
      "Training accuracy: \n",
      "0.6507936507936508\n",
      "Testing accuracy\n",
      "0.6349206349206349\n",
      "16\n",
      "Training accuracy: \n",
      "0.7566137566137566\n",
      "Testing accuracy\n",
      "0.7142857142857143\n",
      "17\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "18\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "19\n",
      "Training accuracy: \n",
      "0.9682539682539683\n",
      "Testing accuracy\n",
      "0.9047619047619048\n",
      "20\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "Avg_training_accuracy 0.9526329050138574\n",
      "Avg_testing_accuracy 0.9516250944822373\n"
     ]
    }
   ],
   "source": [
    "Train_accuracy = 0\n",
    "Test_accuracy = 0\n",
    "for i in range(0,21):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, z[:,i])\n",
    "    #clf = LogisticRegression()\n",
    "    #clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "    y_pred1 = np.zeros((y_train.shape))    #clf.predict(X_train)\n",
    "    y_pred2 = np.zeros((y_test.shape))    #clf.predict(X_test)\n",
    "    print(\"Training accuracy: \")\n",
    "    print(metrics.accuracy_score(y_train,y_pred1))\n",
    "    Train_accuracy = Train_accuracy + metrics.accuracy_score(y_train,y_pred1)\n",
    "    print(\"Testing accuracy\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred2))\n",
    "    Test_accuracy = Test_accuracy + metrics.accuracy_score(y_test,y_pred2)\n",
    "    #print(y_train.shape)\n",
    "Avg_tr_acc = Train_accuracy/21\n",
    "Avg_te_acc = Test_accuracy/21\n",
    "print(\"Avg_training_accuracy\",Avg_tr_acc)\n",
    "print(\"Avg_testing_accuracy\",Avg_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "1\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "1.0\n",
      "2\n",
      "Training accuracy: \n",
      "0.9894179894179894\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "3\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "4\n",
      "Training accuracy: \n",
      "0.9470899470899471\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "5\n",
      "Training accuracy: \n",
      "0.9629629629629629\n",
      "Testing accuracy\n",
      "0.9365079365079365\n",
      "6\n",
      "Training accuracy: \n",
      "0.9682539682539683\n",
      "Testing accuracy\n",
      "0.9523809523809523\n",
      "7\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "8\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "1.0\n",
      "9\n",
      "Training accuracy: \n",
      "0.9735449735449735\n",
      "Testing accuracy\n",
      "0.9523809523809523\n",
      "10\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "11\n",
      "Training accuracy: \n",
      "0.9788359788359788\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "12\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "13\n",
      "Training accuracy: \n",
      "0.9947089947089947\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "14\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "15\n",
      "Training accuracy: \n",
      "0.6613756613756614\n",
      "Testing accuracy\n",
      "0.6031746031746031\n",
      "16\n",
      "Training accuracy: \n",
      "0.7566137566137566\n",
      "Testing accuracy\n",
      "0.7142857142857143\n",
      "17\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "18\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "0.9841269841269841\n",
      "19\n",
      "Training accuracy: \n",
      "0.9470899470899471\n",
      "Testing accuracy\n",
      "0.9682539682539683\n",
      "20\n",
      "Training accuracy: \n",
      "0.9841269841269841\n",
      "Testing accuracy\n",
      "1.0\n",
      "Avg_training_accuracy 0.9536407155454776\n",
      "Avg_testing_accuracy 0.9486016628873772\n"
     ]
    }
   ],
   "source": [
    "Train_accuracy = 0\n",
    "Test_accuracy = 0\n",
    "for i in range(0,21):\n",
    "    print(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, z[:,i])\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "#print(clf.predict(data_test))\n",
    "    y_pred1 = np.zeros((y_train.shape))    #clf.predict(X_train)\n",
    "    y_pred2 = np.zeros((y_test.shape))    #clf.predict(X_test)\n",
    "    print(\"Training accuracy: \")\n",
    "    print(metrics.accuracy_score(y_train,y_pred1))\n",
    "    Train_accuracy = Train_accuracy + metrics.accuracy_score(y_train,y_pred1)\n",
    "    print(\"Testing accuracy\")\n",
    "    print(metrics.accuracy_score(y_test,y_pred2))\n",
    "    Test_accuracy = Test_accuracy + metrics.accuracy_score(y_test,y_pred2)\n",
    "    #print(y_train.shape)\n",
    "Avg_tr_acc = Train_accuracy/21\n",
    "Avg_te_acc = Test_accuracy/21\n",
    "print(\"Avg_training_accuracy\",Avg_tr_acc)\n",
    "print(\"Avg_testing_accuracy\",Avg_te_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
